{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spring 2019 | CS 6400\n",
    "\n",
    "Author: Travis Jefferies\n",
    "Last Updated: 04252019\n",
    "\n",
    "## Efficiency\n",
    "\n",
    "Your database could be the best designed thing in the world, but if it isn't fast enough, nobody will use it! We must first begin with some computer hardware 101.\n",
    "\n",
    "### Computer Architecture 101\n",
    "\n",
    "![](p1.svg)\n",
    "\n",
    "Main memory - RAM - volatile, fast, expensive \\$\\$\\$<br>\n",
    "Secondary Memory - DISK - permanent, slow, big and cheap $<br>\n",
    "* Applications run by the CPU can only query and update data in main memory\n",
    "* Data must be written back to secondary memory after being updated\n",
    "* Only tiny fraction of a real database fits into main memory\n",
    "\n",
    "### Who Cares?\n",
    "\n",
    "We should care about this stuff when considering the difference in access time between main memory and disk:\n",
    "* Main Memory\n",
    "    * 30ns or $3\\times10^{-7}$ sec\n",
    "* Disk\n",
    "    * 10ms or $1\\times10^{-2}$ sec\n",
    "\n",
    "Assuming we have 60 seconds to access things, its $\\frac{\\frac{60}{3\\times10^{-7}}}{\\frac{60}{0.01}}$ or 33,333.33$\\times$ faster to use main memory.\n",
    "* In fact, RAM access time is completely ignored when computing computational cost\n",
    "    * Only disk access time is even considered!\n",
    "    * CPU cost is ignored too in these calculations\n",
    "    \n",
    "### Disk\n",
    "\n",
    "See picture below for an in-depth overview of the disk:\n",
    "\n",
    "![](p2.png)\n",
    "\n",
    "A disk has a number of plates or platters.<br>\n",
    "For each one of the platters, there is a read-write head that accesses the top of the plate, and one that accesses the bottom of the plate.<br>\n",
    "All of the read-write heads are connected together and are operated by an actuator.<br>\n",
    "On each surface, what passes under the read-write in that position is called a track.<br>\n",
    "A collection of tracks is called a cylinder.<br>\n",
    "Each surface is split up into a number of sectors.<br>\n",
    "A sector is the smallest physical unit that could be transported from disk to main memory.\n",
    "* Usually consists  of 512 bytes\n",
    "\n",
    "Blocks have contributions from several sectors.<br>\n",
    "* Typically blocks are 4k bytes or 8 sectors\n",
    "    * Could be 8k or 16k depending on the data we are storing\n",
    "    \n",
    "### Records, Blocks, Files\n",
    "\n",
    "The memory access required for database applications can mainly be thought about as records, blocks, and files.\n",
    "\n",
    "#### Records\n",
    "\n",
    "Records are stored on a block on a disk.<br>\n",
    "\n",
    "![](p3.png)\n",
    "\n",
    "RegularUser(\n",
    "    Email varchar(50),\n",
    "    Sex char(1),\n",
    "    BirthDate datetime,\n",
    "    CurrentCity varchar(50),\n",
    "    Hometown varchar(50)\n",
    ")\n",
    "\n",
    "datetime = 8 bytes<br>\n",
    "record size = 50 + 1 + 8 + 50 + 50 = [1, 160] = 159 bytes<br>\n",
    "\n",
    "#### Blocks\n",
    "\n",
    "Now if we assume the following specs:\n",
    "\n",
    "block size: 4 kb (+metadata)<br>\n",
    "filled: ~80%<br>\n",
    "\n",
    "We can expect the following memory footprint:\n",
    "\n",
    "4,000 $\\times$ 0.8 = 3,200<br>\n",
    "3,200 / 159 is = 20.126 records/block<br>\n",
    "\n",
    "So what do we do with the remaining 0.874 record?\n",
    "\n",
    "![](p4.png)\n",
    "\n",
    "If we decide to go with the option on the left - where 0.126 of one record starts in one block and the other 0.874 record is represented in another block, we have what is called a *spanned representation*.<br>\n",
    "\n",
    "The default action in most database systems is to run with unspanned representations, simply to avoid the processing that's needed to break off records.\n",
    "* Obviously if you have record sizes that are larger than block sizes than you don't have a chice but to run with the spanned representation.\n",
    "\n",
    "Now that we have the concept of Blocks, we can create Files.\n",
    "\n",
    "#### Files\n",
    "\n",
    "Files are Blocks linked together by pointers.<br>\n",
    "\n",
    "![](p5.png)\n",
    "\n",
    "Assuming the following specs:\n",
    "\n",
    "block pointer size: 4 bytes (true for 32 bit architecture)<br>\n",
    "\\# Records: 4,000,000<br>\n",
    "block size: 4 kb\n",
    "\n",
    "Assuming we can fit ~20 records/block, 4,000,000 records will require $\\frac{4,000,000 \\text{records}}{20 \\frac{\\text{records}}{block}} \\approx 200,000$ Blocks\n",
    "\n",
    "So we can expect ~$200,000 \\times 4\\text{kb} \\approx 800\\text{MB}$ size file on disk.\n",
    "\n",
    "### Compute Transport Time from Disk to Main Memory\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "* Seek time: 3-8 ms\n",
    "* Rotational Delay: 2-3 ms\n",
    "* Transfer time: 0.5-1.0 ms\n",
    "* Total: 5-12 ms\n",
    "\n",
    "0.01 sec or 10 ms per page fault.<br>\n",
    "\n",
    "What if instead of picking up 1 block at a time, we chose to pick up 250 blocks per seek-rotation?<br>\n",
    "These are called ***extent transfers***.\n",
    "\n",
    "Normally such an operation would cost $250 \\text{ blocks} \\times 10\\frac{\\text{ ms}}{\\text{block}} \\approx 2.5 \\text{ secs}$.<br>\n",
    "\n",
    "Using *extent transfers* we can do the same operation for $\\approx 0.25 \\text{ secs}$.\n",
    "* Extent transfers only incur seek time and rotational delay on finding the first block\n",
    "    * From that point on it is straight transfer time, seek-rotation delay is elminated\n",
    "    \n",
    "The downside to using *extent transfers* is we will probably need more buffer space.<br>\n",
    "Whenever we move data from the disk into main memory or from main memory back to disk, we need good buffer management strategies.\n",
    "* One of the most commonly used strategies is Least Recently Used (LRU)\n",
    "    * If we run out of buffer space and need to free up space in main memory for the data being transfered from disk, we find what is least recently used and overwrite that.\n",
    "    * Philosophy being *We haven't used it in awhile, were probably not gonna use it next.\"\n",
    "    \n",
    "LRU is ideal for merge joins.\n",
    "\n",
    "* LRU really struggles with nested loop joins\n",
    "    * MRU or Most Recently Used is ideal for nested loop joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.5/0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
